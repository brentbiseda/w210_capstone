{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'mids-w210-summer-2020-medical-assistant'\n",
    "gz_key = 'data.zip'\n",
    "parque_key='data.parque'\n",
    "csv_key='data.csv'\n",
    "s3_location='s3://{}/{}/{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "from io import StringIO # python3; python2: BytesIO \n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk-pom:1.10.34,org.apache.hadoop:hadoop-aws:2.7.2 pyspark-shell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pyspark.sql import SparkSession\\n\\nspark = SparkSession.builder   .master(\"local[*]\")   .appName(\"GZToCSV\")   .getOrCreate()'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "  .master(\"local[*]\") \\\n",
    "  .appName(\"GZToCSV\") \\\n",
    "  .getOrCreate()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_to_read=['ADMISSIONS', 'CALLOUT', 'CAREGIVERS', 'CHARTEVENTS', 'CPTEVENTS'\n",
    "                   , 'DATETIMEEVENTS', 'DIAGNOSES_ICD', 'DRGCODES', 'D_CPT', 'D_ICD_DIAGNOSES'\n",
    "                   , 'D_ICD_PROCEDURES', 'D_ITEMS', 'D_LABITEMS', 'ICUSTAYS', 'INPUTEVENTS_CV'\n",
    "                   , 'INPUTEVENTS_MV', 'LABEVENTS', 'MICROBIOLOGYEVENTS', 'NOTEEVENTS'\n",
    "                   , 'OUTPUTEVENTS', 'PATIENTS', 'PRESCRIPTIONS', 'PROCEDUREEVENTS_MV'\n",
    "                   , 'PROCEDURES_ICD', 'SERVICES', 'TRANSFERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADMISSIONS', 'CALLOUT']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files_to_read[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_location' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fd35e5756536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_location' is not defined"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv(data_location,compression='gzip', header=0, sep=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file ADMISSIONS\n",
      "gz_data_location=s3://mids-w210-summer-2020-medical-assistant/data.zip/ADMISSIONS.csv.gz\n",
      "Read into df\n",
      "Working on file CALLOUT\n",
      "gz_data_location=s3://mids-w210-summer-2020-medical-assistant/data.zip/CALLOUT.csv.gz\n",
      "Read into df\n",
      "Working on file CAREGIVERS\n",
      "gz_data_location=s3://mids-w210-summer-2020-medical-assistant/data.zip/CAREGIVERS.csv.gz\n",
      "Read into df\n",
      "Working on file CPTEVENTS\n",
      "gz_data_location=s3://mids-w210-summer-2020-medical-assistant/data.zip/CPTEVENTS.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (4,5,7,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read into df\n",
      "Working on file DATETIMEEVENTS\n",
      "gz_data_location=s3://mids-w210-summer-2020-medical-assistant/data.zip/DATETIMEEVENTS.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read into df\n"
     ]
    }
   ],
   "source": [
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "for cur_file in csv_files_to_read:\n",
    "    if cur_file == \"CHARTEVENTS\" or cur_file == \"INPUTEVENTS_CV\" or cur_file == \"INPUTEVENTS_MV\":\n",
    "        continue\n",
    "    print('Working on file '+cur_file)\n",
    "    gz_data_location = s3_location.format(bucket, gz_key,cur_file+\".csv.gz\" )\n",
    "    print('gz_data_location='+gz_data_location)\n",
    "    #df = spark.textFile(gz_data_location, header = True)\n",
    "    #rdd = spark.sparkContext.textFile(gz_data_location)\n",
    "    #df=rdd.toDF()\n",
    "    #df = spark.read.csv(gz_data_location, sep=',')\n",
    "    data = pd.read_csv(gz_data_location,compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "    #print(data.head())\n",
    "    print(\"Read into df\")\n",
    "    csv_data_location=s3_location.format(bucket, csv_key,cur_file )\n",
    "    #data.to_csv(csv_data_location, index=False)\n",
    "    \n",
    "\n",
    "    csv_buffer = StringIO()\n",
    "    data.to_csv(csv_buffer)\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_resource.Object(bucket, csv_key+\"/\"+cur_file+\".csv\").put(Body=csv_buffer.getvalue())\n",
    "    #df.write.mode('overwrite').parquet(parque_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
