{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "#import torch\n",
    "#from transformers import AutoTokenizer, AutoModel\n",
    "#import re\n",
    "#import string\n",
    "import numpy as np\n",
    "#import pydot\n",
    "#from nltk.corpus import stopwords \n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem import LancasterStemmer\n",
    "#from simpletransformers.classification import MultiLabelClassificationModel\n",
    "#import logging\n",
    "#import custom_sentence_tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy import stats\n",
    "#from ast import literal_eval\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import gc\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Reshape\n",
    "from keras.layers import GlobalMaxPooling1D,Conv2D, Conv1D, AveragePooling2D, MaxPooling1D, AveragePooling1D, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "#from sklearn.decomposition import PCA\n",
    "import _pickle as cPickle\n",
    "import io\n",
    "import time\n",
    "import sys\n",
    "import boto3\n",
    "from boto3.s3.transfer import TransferConfig\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Embeddings (X) and Labels (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.87386226654053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time.time()\n",
    "infile = None\n",
    "infile = open(\"embeddings_evaluation\",'rb')\n",
    "embeddings_evaluation = cPickle.load(infile)\n",
    "infile.close()\n",
    "del(infile)\n",
    "print(time.time()-now)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.81072735786438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time.time()\n",
    "infile = None\n",
    "infile = open(\"embeddings_7.1\",'rb')\n",
    "embeddings = cPickle.load(infile)\n",
    "infile.close()\n",
    "del(infile)\n",
    "print(time.time()-now)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.update(embeddings_evaluation)\n",
    "pickle.dump( embeddings, open( \"/home/ec2-user/SageMaker/embeddings.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(embeddings_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.81700110435486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time.time()\n",
    "infile = None\n",
    "infile = open(\"embeddings.p\",'rb')\n",
    "embeddings = cPickle.load(infile)\n",
    "infile.close()\n",
    "del(infile)\n",
    "print(time.time()-now)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_np_complete = np.array(list(embeddings.items()))\n",
    "del(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load chapter model and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load chapeter model weights\n",
    "chapter_model = None\n",
    "json_file = open('model_num_cnn2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "chapter_model = model_from_json(loaded_model_json)\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "# load weights into new model\n",
    "chapter_model.load_weights(\"model_num_cnn2.h5\")\n",
    "chapter_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(embeddings):\n",
    "    max_sentence = 20\n",
    "    padding = max_sentence - len(embeddings)\n",
    "    if padding > 0:\n",
    "        padding_shape = (padding, 256, 768)\n",
    "        pad = np.zeros(padding*256*768).reshape(padding_shape)\n",
    "        return np.append(embeddings, pad, axis = 0).astype('float16')\n",
    "    else:\n",
    "        return embeddings\n",
    "    \n",
    "def split_for_train(HADM_ID_LIST, CHAPTER_PIVOT_DF, embeddings_concat):\n",
    "    HADM_ID_DF = None\n",
    "    loaded_model = None\n",
    "    HADM_ID_DF =  pd.DataFrame(data=HADM_ID_LIST, columns=['HADM_ID'])\n",
    "    CHAPTER_PIVOT_DF_COPY = HADM_ID_DF.set_index('HADM_ID')\\\n",
    "                    .join(CHAPTER_PIVOT_DF, how='left').copy(deep=False)\n",
    "    CHAPTER_PIVOT_NP = np.array(CHAPTER_PIVOT_DF_COPY)\n",
    "    return train_test_split(embeddings_concat, CHAPTER_PIVOT_NP, test_size=0.2)\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "import tensorflow as tf\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    #p1 = tn / (tn + fn + K.epsilon())\n",
    "    #r1 = tn / (tn + fp + K.epsilon())\n",
    "    \n",
    "    f1 = p*r / (p+r+K.epsilon())\n",
    "    #+ p1*r1 / (p1+r1+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)\n",
    "\n",
    "def get_model(label_len):\n",
    "    #define model - STATIC LAYERS\n",
    "    model = Sequential()\n",
    "    for layer in chapter_model.layers[:4]:\n",
    "        layer.trainable = False\n",
    "        model.add(layer)\n",
    "    \n",
    "    #independent_model = True\n",
    "    #LEARNING LAYERS\n",
    "    if label_len <=4:\n",
    "        print('model 1')\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(label_len, activation='sigmoid'))\n",
    "    elif label_len >4:\n",
    "        print('model 2')\n",
    "        #model.add(Conv1D(label_len, 4))\n",
    "        #model.add(AveragePooling1D(pool_size=2))\n",
    "        #model.add(Flatten())\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(2048))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(128))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        #model.add(Dropout(0.3))\n",
    "        model.add(Dense(label_len, activation='sigmoid'))\n",
    "    elif independent_model:\n",
    "        print('model 3')\n",
    "        deep_inputs = Input(shape=(20*256,768))\n",
    "        LSTM_Layer_1 = LSTM(128)(deep_inputs)\n",
    "        dense_layer_1 = Dense(label_len, activation='sigmoid')(LSTM_Layer_1)\n",
    "        model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n",
    "        return model\n",
    "    model = Model(inputs=model.input, outputs=model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loop on individual therapy area (bag of models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============Started 320_389.csv============\n",
      "320_389.csv orginal shape: (3834, 2)\n",
      "320_389.csv Padding complete\n",
      "320_389.csv modified shape: (3834, 5120, 768)\n",
      "Train and Test Shapre: (3067, 5120, 768), (767, 5120, 768), (3067, 4), (767, 4)\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "history_list = []\n",
    "#file_name_LIST = ['001_139.csv','140_239.csv','240_279.csv','280_289.csv','290_319.csv','320_389.csv','390_459.csv'\n",
    "#,'460_519.csv','520_579.csv','580_629.csv','630_679__740_759__760_779.csv', '710-739.csv','780-799.csv','800-999.csv','E_V.csv']\n",
    "1. #file_name_LIST = ['001_139.csv','140_239.csv','240_279.csv','800-999.csv']\n",
    "file_name_LIST = ['320_389.csv']\n",
    "#file_name_LIST = ['630_679__740_759__760_779.csv']\n",
    "\n",
    "for file_name in file_name_LIST:\n",
    "    print('\\n\\n============Started '+file_name+'============')\n",
    "    CHAPTER_PIVOT_DF = pd.read_csv('Layer-2/'+file_name, sep=',', header = 0)\\\n",
    "                        .astype({'HADM_ID': 'str'}).set_index('HADM_ID')\n",
    "    HADM_ID_LIST = list(CHAPTER_PIVOT_DF.index)\n",
    "    embeddings_np = embeddings_np_complete[np.isin(embeddings_np_complete[:,0], HADM_ID_LIST)]\n",
    "    print(file_name+' orginal shape: '+str(embeddings_np.shape))\n",
    "    HADM_ID_LIST = embeddings_np[:,0].copy()\n",
    "    embeddings = embeddings_np[:,1].copy()\n",
    "    \n",
    "    #Zero Pad embeddings\n",
    "    embeddings_padded = [padding(embeddings_ITEM) for embeddings_ITEM in embeddings]\n",
    "    del(embeddings)\n",
    "    gc.collect()\n",
    "    print(file_name+' Padding complete')\n",
    "\n",
    "    #Reshape embeddings\n",
    "    #embeddings_concat = np.array([np.concatenate(i) for i in embeddings_padded])\n",
    "    embeddings_concat = np.array(embeddings_padded).reshape(len(embeddings_padded), 20*256, 768)\n",
    "    print(file_name+' modified shape: '+str(embeddings_concat.shape))\n",
    "    del(embeddings_padded)\n",
    "    gc.collect()\n",
    "    \n",
    "    X_train2, X_test2, y_train2, y_test2 = split_for_train(HADM_ID_LIST, CHAPTER_PIVOT_DF, embeddings_concat)\n",
    "    print('Train and Test Shapre: '+str(X_train2.shape)+', '+str(X_test2.shape)+', '+str(y_train2.shape)+', '+str(y_test2.shape))\n",
    "    X_val = X_test2[:int(0.25*len(X_test2))]\n",
    "    y_val = y_test2[:int(0.25*len(y_test2))]\n",
    "    del(HADM_ID_LIST)\n",
    "    del(CHAPTER_PIVOT_DF)\n",
    "    del(embeddings_concat)\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class_value = ((y_train2.shape[0]*y_train2.shape[1])/np.sum(y_train2, axis=0))*(max(np.sum(y_train2, axis = 0))*(1/np.sum(y_train2, axis = 0)))\n",
    "class_weight = {}\n",
    "for i, class_value_item in enumerate(class_value):\n",
    "    class_weight[i] = class_value_item\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 11.412093023255814,\n",
       " 1: 35.55884502037041,\n",
       " 2: 49.14990831979249,\n",
       " 3: 14.46023957676599}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.41209302, 35.55884502, 49.14990832, 14.46023958])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_train2.shape[0]*y_train2.shape[1])/np.sum(y_train2, axis=0))*(max(np.sum(y_train2, axis = 0))*(1/np.sum(y_train2, axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1\n",
      "Train on 3067 samples, validate on 191 samples\n",
      "Epoch 1/5\n",
      "3067/3067 [==============================] - 69s 22ms/step - loss: 0.7598 - get_f1: 0.3291 - accuracy: 0.6810 - val_loss: 0.5255 - val_get_f1: 0.2694 - val_accuracy: 0.7513\n",
      "Epoch 2/5\n",
      "3067/3067 [==============================] - 68s 22ms/step - loss: 0.5712 - get_f1: 0.4395 - accuracy: 0.7430 - val_loss: 0.5159 - val_get_f1: 0.2927 - val_accuracy: 0.7448\n",
      "Epoch 3/5\n",
      "3067/3067 [==============================] - 68s 22ms/step - loss: 0.5001 - get_f1: 0.4884 - accuracy: 0.7680 - val_loss: 0.5137 - val_get_f1: 0.3981 - val_accuracy: 0.7461\n",
      "Epoch 4/5\n",
      "3067/3067 [==============================] - 67s 22ms/step - loss: 0.4577 - get_f1: 0.5466 - accuracy: 0.7912 - val_loss: 0.5251 - val_get_f1: 0.4191 - val_accuracy: 0.7317\n",
      "Epoch 5/5\n",
      "3067/3067 [==============================] - 67s 22ms/step - loss: 0.4188 - get_f1: 0.6043 - accuracy: 0.8138 - val_loss: 0.5498 - val_get_f1: 0.3519 - val_accuracy: 0.7408\n",
      "Model evaluation 320_389.csv\n",
      "767/767 [==============================] - 14s 19ms/step\n",
      "[0.5562837114545481, 0.3257567286491394, 0.7323989272117615]\n",
      "============completed 320_389.csv============\n"
     ]
    }
   ],
   "source": [
    "    #call model\n",
    "    label_len = y_train2.shape[1]\n",
    "    model = get_model(label_len)\n",
    "    opt = keras.optimizers.Adam(lr=0.0001)\n",
    "    #'binary_crossentropy'\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[get_f1, 'accuracy'])\n",
    "    history = model.fit(X_train2, y_train2, epochs=5,batch_size=32, verbose=1, validation_data = (X_val,y_val))\n",
    "    #history = model.fit(data_generator(X_train2, y_train2, BS, aug_num), steps_per_epoch = SPE, epochs=10, verbose=1, class_weight=class_weight)\n",
    "    #evaluate model\n",
    "    print('Model evaluation '+file_name)\n",
    "    score = model.evaluate(X_test2, y_test2, verbose=1)\n",
    "    print(score)\n",
    "    \n",
    "    #save model evaluation and history metrics\n",
    "    score_list.append(score)\n",
    "    history_list.append(history.history)\n",
    "    \n",
    "    #save model\n",
    "    model_json = model.to_json()\n",
    "    with open(\"/home/ec2-user/SageMaker/Models/model_\"+file_name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"/home/ec2-user/SageMaker/Models/model_\"+file_name+\".h5\")\n",
    "    print('============completed '+file_name+'============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_num = 3\n",
    "BS = 10\n",
    "#steps_per_epoch\n",
    "SPE = (len(y_train2)*aug_num)/((1+aug_num)*BS)\n",
    "\n",
    "def data_generator(X_train2, y_train2, BS, aug_num):\n",
    "    N = len(y_train2)\n",
    "    X_yield = []\n",
    "    y_yield = []\n",
    "    pad = [[0 for i in range(768)] for j in range(20*256)]\n",
    "    #pad = np.zeros(20*256*768).reshape(20*256, 768)\n",
    "    rand_LIST = np.array([i for i in range(20*256)])\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        for i in range(N):\n",
    "            x = X_train2[i]\n",
    "            y = y_train2[i]\n",
    "            non_zero_x = sum(x[:,0]!=0)\n",
    "\n",
    "            x_list = [x]\n",
    "            for aug in range(aug_num):\n",
    "                \n",
    "                rand_NEW = rand_LIST[:non_zero_x]\n",
    "                random.shuffle(rand_NEW)\n",
    "                rand_NEW = np.append(rand_NEW,[n for n in range(non_zero_x, 20*256)], axis=0).astype('int')\n",
    "                #print(rand_NEW)\n",
    "                x_list.append([x[n] for n in rand_NEW.tolist()])\n",
    "\n",
    "            y_list = [y for n in range(len(x_list))]\n",
    "            \n",
    "            if (i+1)%(BS+1) == 0:\n",
    "                yield (np.array(X_yield), np.array(Y_yield))\n",
    "            elif i%(BS+1) == 0:\n",
    "                X_yield = x_list\n",
    "                Y_yield = y_list\n",
    "            else:\n",
    "                X_yield = np.append(X_yield, x_list, axis=0).astype('float16')\n",
    "                Y_yield = np.append(Y_yield, y_list, axis=0).astype('int') \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============Started 001_139.csv============\n",
      "001_139.csv orginal shape: (5135, 2)\n",
      "001_139.csv Padding complete\n",
      "001_139.csv modified shape: (5135, 5120, 768)\n",
      "Train and Test Shapre: (4108, 5120, 768), (1027, 5120, 768), (4108, 4), (1027, 4)\n",
      "model 1\n",
      "Train on 4108 samples, validate on 256 samples\n",
      "Epoch 1/4\n",
      "4108/4108 [==============================] - 86s 21ms/step - loss: 0.5392 - get_f1: 0.5945 - accuracy: 0.7622 - val_loss: 0.5104 - val_get_f1: 0.5871 - val_accuracy: 0.7695\n",
      "Epoch 2/4\n",
      "4108/4108 [==============================] - 86s 21ms/step - loss: 0.4600 - get_f1: 0.6467 - accuracy: 0.8003 - val_loss: 0.5071 - val_get_f1: 0.6013 - val_accuracy: 0.7725\n",
      "Epoch 3/4\n",
      "4108/4108 [==============================] - 86s 21ms/step - loss: 0.4150 - get_f1: 0.6810 - accuracy: 0.8169 - val_loss: 0.5055 - val_get_f1: 0.5986 - val_accuracy: 0.7725\n",
      "Epoch 4/4\n",
      "4108/4108 [==============================] - 86s 21ms/step - loss: 0.3651 - get_f1: 0.7314 - accuracy: 0.8431 - val_loss: 0.5160 - val_get_f1: 0.6036 - val_accuracy: 0.7676\n",
      "Model evaluation 001_139.csv\n",
      "1027/1027 [==============================] - 20s 19ms/step\n",
      "[0.49797390826489, 0.6261672973632812, 0.7843232750892639]\n",
      "============completed 001_139.csv============\n",
      "\n",
      "\n",
      "============Started 140_239.csv============\n",
      "140_239.csv orginal shape: (2369, 2)\n",
      "140_239.csv Padding complete\n",
      "140_239.csv modified shape: (2369, 5120, 768)\n",
      "Train and Test Shapre: (1895, 5120, 768), (474, 5120, 768), (1895, 3), (474, 3)\n",
      "model 1\n",
      "Train on 1895 samples, validate on 118 samples\n",
      "Epoch 1/4\n",
      "1895/1895 [==============================] - 39s 21ms/step - loss: 0.5648 - get_f1: 0.6753 - accuracy: 0.7249 - val_loss: 0.5199 - val_get_f1: 0.7459 - val_accuracy: 0.7881\n",
      "Epoch 2/4\n",
      "1895/1895 [==============================] - 39s 21ms/step - loss: 0.4522 - get_f1: 0.7500 - accuracy: 0.7880 - val_loss: 0.5275 - val_get_f1: 0.7530 - val_accuracy: 0.7910\n",
      "Epoch 3/4\n",
      "1895/1895 [==============================] - 39s 21ms/step - loss: 0.3953 - get_f1: 0.7930 - accuracy: 0.8211 - val_loss: 0.5351 - val_get_f1: 0.7292 - val_accuracy: 0.7740\n",
      "Epoch 4/4\n",
      "1895/1895 [==============================] - 39s 21ms/step - loss: 0.3257 - get_f1: 0.8417 - accuracy: 0.8628 - val_loss: 0.5389 - val_get_f1: 0.7435 - val_accuracy: 0.7797\n",
      "Model evaluation 140_239.csv\n",
      "474/474 [==============================] - 9s 19ms/step\n",
      "[0.5173844861078866, 0.7325862050056458, 0.7700421810150146]\n",
      "============completed 140_239.csv============\n",
      "\n",
      "\n",
      "============Started 240_279.csv============\n",
      "240_279.csv orginal shape: (6263, 2)\n",
      "240_279.csv Padding complete\n",
      "240_279.csv modified shape: (6263, 5120, 768)\n",
      "Train and Test Shapre: (5010, 5120, 768), (1253, 5120, 768), (5010, 4), (1253, 4)\n",
      "model 1\n",
      "Train on 5010 samples, validate on 313 samples\n",
      "Epoch 1/4\n",
      "5010/5010 [==============================] - 105s 21ms/step - loss: 0.5728 - get_f1: 0.5256 - accuracy: 0.7214 - val_loss: 0.5583 - val_get_f1: 0.5092 - val_accuracy: 0.7204\n",
      "Epoch 2/4\n",
      "5010/5010 [==============================] - 104s 21ms/step - loss: 0.5112 - get_f1: 0.5855 - accuracy: 0.7553 - val_loss: 0.5553 - val_get_f1: 0.5289 - val_accuracy: 0.7212\n",
      "Epoch 3/4\n",
      "5010/5010 [==============================] - 104s 21ms/step - loss: 0.4651 - get_f1: 0.6418 - accuracy: 0.7820 - val_loss: 0.5542 - val_get_f1: 0.5549 - val_accuracy: 0.7364\n",
      "Epoch 4/4\n",
      "5010/5010 [==============================] - 104s 21ms/step - loss: 0.4156 - get_f1: 0.6912 - accuracy: 0.8079 - val_loss: 0.5602 - val_get_f1: 0.5459 - val_accuracy: 0.7204\n",
      "Model evaluation 240_279.csv\n",
      "1253/1253 [==============================] - 24s 19ms/step\n",
      "[0.5580913116241205, 0.5607442855834961, 0.7272545695304871]\n",
      "============completed 240_279.csv============\n",
      "\n",
      "\n",
      "============Started 280_289.csv============\n",
      "280_289.csv orginal shape: (6212, 2)\n",
      "280_289.csv Padding complete\n",
      "280_289.csv modified shape: (6212, 5120, 768)\n",
      "Train and Test Shapre: (4969, 5120, 768), (1243, 5120, 768), (4969, 3), (1243, 3)\n",
      "model 1\n",
      "Train on 4969 samples, validate on 310 samples\n",
      "Epoch 1/4\n",
      "4969/4969 [==============================] - 104s 21ms/step - loss: 0.5657 - get_f1: 0.5440 - accuracy: 0.7035 - val_loss: 0.4849 - val_get_f1: 0.5971 - val_accuracy: 0.7581\n",
      "Epoch 2/4\n",
      "4969/4969 [==============================] - 103s 21ms/step - loss: 0.4840 - get_f1: 0.6386 - accuracy: 0.7709 - val_loss: 0.4903 - val_get_f1: 0.6182 - val_accuracy: 0.7591\n",
      "Epoch 3/4\n",
      "4969/4969 [==============================] - 103s 21ms/step - loss: 0.4264 - get_f1: 0.6964 - accuracy: 0.8054 - val_loss: 0.4983 - val_get_f1: 0.6137 - val_accuracy: 0.7548\n",
      "Epoch 4/4\n",
      "4969/4969 [==============================] - 103s 21ms/step - loss: 0.3747 - get_f1: 0.7469 - accuracy: 0.8369 - val_loss: 0.5122 - val_get_f1: 0.6192 - val_accuracy: 0.7559\n",
      "Model evaluation 280_289.csv\n",
      "1243/1243 [==============================] - 24s 19ms/step\n",
      "[0.5245444894748068, 0.6203137636184692, 0.7567712068557739]\n",
      "============completed 280_289.csv============\n",
      "\n",
      "\n",
      "============Started 290_319.csv============\n",
      "290_319.csv orginal shape: (5661, 2)\n",
      "290_319.csv Padding complete\n",
      "290_319.csv modified shape: (5661, 5120, 768)\n",
      "Train and Test Shapre: (4528, 5120, 768), (1133, 5120, 768), (4528, 4), (1133, 4)\n",
      "model 1\n",
      "Train on 4528 samples, validate on 283 samples\n",
      "Epoch 1/4\n",
      "4528/4528 [==============================] - 95s 21ms/step - loss: 0.6063 - get_f1: 0.2383 - accuracy: 0.6848 - val_loss: 0.5713 - val_get_f1: 0.1667 - val_accuracy: 0.6996\n",
      "Epoch 2/4\n",
      "4528/4528 [==============================] - 94s 21ms/step - loss: 0.5450 - get_f1: 0.3384 - accuracy: 0.7226 - val_loss: 0.5662 - val_get_f1: 0.2336 - val_accuracy: 0.6988\n",
      "Epoch 3/4\n",
      "4528/4528 [==============================] - 94s 21ms/step - loss: 0.4966 - get_f1: 0.4587 - accuracy: 0.7590 - val_loss: 0.5720 - val_get_f1: 0.2742 - val_accuracy: 0.6961\n",
      "Epoch 4/4\n",
      "4528/4528 [==============================] - 94s 21ms/step - loss: 0.4470 - get_f1: 0.5533 - accuracy: 0.7895 - val_loss: 0.5745 - val_get_f1: 0.3086 - val_accuracy: 0.7120\n",
      "Model evaluation 290_319.csv\n",
      "1133/1133 [==============================] - 22s 19ms/step\n",
      "[0.5793024736069412, 0.29727470874786377, 0.7113857269287109]\n",
      "============completed 290_319.csv============\n",
      "\n",
      "\n",
      "============Started 320_389.csv============\n",
      "320_389.csv orginal shape: (3834, 2)\n",
      "320_389.csv Padding complete\n",
      "320_389.csv modified shape: (3834, 5120, 768)\n",
      "Train and Test Shapre: (3067, 5120, 768), (767, 5120, 768), (3067, 4), (767, 4)\n",
      "model 1\n",
      "Train on 3067 samples, validate on 191 samples\n",
      "Epoch 1/4\n",
      "3067/3067 [==============================] - 64s 21ms/step - loss: 0.5802 - get_f1: 0.2231 - accuracy: 0.7103 - val_loss: 0.5480 - val_get_f1: 0.1215 - val_accuracy: 0.7395\n",
      "Epoch 2/4\n",
      "3067/3067 [==============================] - 63s 21ms/step - loss: 0.4855 - get_f1: 0.3623 - accuracy: 0.7676 - val_loss: 0.5488 - val_get_f1: 0.2292 - val_accuracy: 0.7330\n",
      "Epoch 3/4\n",
      "3067/3067 [==============================] - 64s 21ms/step - loss: 0.4334 - get_f1: 0.4960 - accuracy: 0.7991 - val_loss: 0.5569 - val_get_f1: 0.2597 - val_accuracy: 0.7264\n",
      "Epoch 4/4\n",
      "3067/3067 [==============================] - 64s 21ms/step - loss: 0.3837 - get_f1: 0.5939 - accuracy: 0.8270 - val_loss: 0.5602 - val_get_f1: 0.3129 - val_accuracy: 0.7160\n",
      "Model evaluation 320_389.csv\n",
      "767/767 [==============================] - 15s 19ms/step\n",
      "[0.5234892479443954, 0.3680371344089508, 0.7473924160003662]\n",
      "============completed 320_389.csv============\n",
      "\n",
      "\n",
      "============Started 390_459.csv============\n",
      "390_459.csv orginal shape: (10831, 2)\n",
      "390_459.csv Padding complete\n",
      "390_459.csv modified shape: (10831, 5120, 768)\n",
      "Train and Test Shapre: (8664, 5120, 768), (2167, 5120, 768), (8664, 6), (2167, 6)\n",
      "model 2\n",
      "Train on 8664 samples, validate on 541 samples\n",
      "Epoch 1/4\n",
      "8664/8664 [==============================] - 215s 25ms/step - loss: 0.5902 - get_f1: 0.3726 - accuracy: 0.6868 - val_loss: 0.5362 - val_get_f1: 0.4491 - val_accuracy: 0.7335\n",
      "Epoch 2/4\n",
      "8664/8664 [==============================] - 214s 25ms/step - loss: 0.5318 - get_f1: 0.4598 - accuracy: 0.7348 - val_loss: 0.5229 - val_get_f1: 0.4608 - val_accuracy: 0.7471\n",
      "Epoch 3/4\n",
      "8664/8664 [==============================] - 214s 25ms/step - loss: 0.5059 - get_f1: 0.5065 - accuracy: 0.7508 - val_loss: 0.5219 - val_get_f1: 0.5067 - val_accuracy: 0.7446\n",
      "Epoch 4/4\n",
      "8664/8664 [==============================] - 215s 25ms/step - loss: 0.4822 - get_f1: 0.5459 - accuracy: 0.7659 - val_loss: 0.5211 - val_get_f1: 0.5078 - val_accuracy: 0.7474\n",
      "Model evaluation 390_459.csv\n",
      "2167/2167 [==============================] - 50s 23ms/step\n",
      "[0.515313947508838, 0.4989098310470581, 0.7444238066673279]\n",
      "============completed 390_459.csv============\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "history_list = []\n",
    "file_name_LIST = ['001_139.csv','140_239.csv','240_279.csv','280_289.csv','290_319.csv','320_389.csv','390_459.csv'\n",
    ",'460_519.csv','520_579.csv','580_629.csv','630_679__740_759__760_779.csv', '710-739.csv','780-799.csv','800-999.csv','E_V.csv']\n",
    "1. #file_name_LIST = ['001_139.csv','140_239.csv','240_279.csv','800-999.csv']\n",
    "#file_name_LIST = ['240_279_1.csv']\n",
    "#file_name_LIST = ['630_679__740_759__760_779.csv']\n",
    "\n",
    "for file_name in file_name_LIST:\n",
    "    print('\\n\\n============Started '+file_name+'============')\n",
    "    CHAPTER_PIVOT_DF = pd.read_csv('Layer-2/'+file_name, sep=',', header = 0)\\\n",
    "                        .astype({'HADM_ID': 'str'}).set_index('HADM_ID')\n",
    "    HADM_ID_LIST = list(CHAPTER_PIVOT_DF.index)\n",
    "    embeddings_np = embeddings_np_complete[np.isin(embeddings_np_complete[:,0], HADM_ID_LIST)]\n",
    "    print(file_name+' orginal shape: '+str(embeddings_np.shape))\n",
    "    HADM_ID_LIST = embeddings_np[:,0].copy()\n",
    "    embeddings = embeddings_np[:,1].copy()\n",
    "    \n",
    "    #Zero Pad embeddings\n",
    "    embeddings_padded = [padding(embeddings_ITEM) for embeddings_ITEM in embeddings]\n",
    "    del(embeddings)\n",
    "    gc.collect()\n",
    "    print(file_name+' Padding complete')\n",
    "\n",
    "    #Reshape embeddings\n",
    "    #embeddings_concat = np.array([np.concatenate(i) for i in embeddings_padded])\n",
    "    embeddings_concat = np.array(embeddings_padded).reshape(len(embeddings_padded), 20*256, 768)\n",
    "    print(file_name+' modified shape: '+str(embeddings_concat.shape))\n",
    "    del(embeddings_padded)\n",
    "    gc.collect()\n",
    "    \n",
    "    X_train2, X_test2, y_train2, y_test2 = split_for_train(HADM_ID_LIST, CHAPTER_PIVOT_DF, embeddings_concat)\n",
    "    print('Train and Test Shapre: '+str(X_train2.shape)+', '+str(X_test2.shape)+', '+str(y_train2.shape)+', '+str(y_test2.shape))\n",
    "    X_val = X_test2[:int(0.25*len(X_test2))]\n",
    "    y_val = y_test2[:int(0.25*len(y_test2))]\n",
    "    del(HADM_ID_LIST)\n",
    "    del(CHAPTER_PIVOT_DF)\n",
    "    del(embeddings_concat)\n",
    "    gc.collect()\n",
    "    \n",
    "    #call model\n",
    "    label_len = y_train2.shape[1]\n",
    "    model = get_model(label_len)\n",
    "    opt = keras.optimizers.Adam(lr=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[get_f1, 'accuracy'])\n",
    "    history = model.fit(X_train2, y_train2, epochs=4,batch_size=32, verbose=1, validation_data = (X_val,y_val))\n",
    "    \n",
    "    #evaluate model\n",
    "    print('Model evaluation '+file_name)\n",
    "    score = model.evaluate(X_test2, y_test2, verbose=1)\n",
    "    print(score)\n",
    "    \n",
    "    #save model evaluation and history metrics\n",
    "    score_list.append(score)\n",
    "    history_list.append(history.history)\n",
    "    \n",
    "    #save model\n",
    "    model_json = model.to_json()\n",
    "    with open(\"/home/ec2-user/SageMaker/Models/model_\"+file_name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"/home/ec2-user/SageMaker/Models/model_\"+file_name+\".h5\")\n",
    "    print('============completed '+file_name+'============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'001_139.csv','140_239.csv','240_279.csv','800-999.csv'\n",
    "# Run 800-999 and 240-279 with more epochs: 6 and 10\n",
    "pickle.dump( score_list, open( \"/home/ec2-user/SageMaker/score_list.p\", \"wb\" ) )\n",
    "pickle.dump( history_list, open( \"/home/ec2-user/SageMaker/history_list.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============Started 460_519.csv============\n",
      "460_519.csv orginal shape: (9021, 2)\n",
      "460_519.csv Padding complete\n",
      "460_519.csv modified shape: (9021, 5120, 768)\n",
      "Train and Test Shapre: (7216, 5120, 768), (1805, 5120, 768), (7216, 5), (1805, 5)\n",
      "model 2\n",
      "Train on 7216 samples, validate on 451 samples\n",
      "Epoch 1/4\n",
      "7216/7216 [==============================] - 179s 25ms/step - loss: 0.5764 - get_f1: 0.3256 - accuracy: 0.7073 - val_loss: 0.5286 - val_get_f1: 0.2915 - val_accuracy: 0.7446\n",
      "Epoch 2/4\n",
      "7216/7216 [==============================] - 208s 29ms/step - loss: 0.5262 - get_f1: 0.4101 - accuracy: 0.7417 - val_loss: 0.5229 - val_get_f1: 0.3737 - val_accuracy: 0.7534\n",
      "Epoch 3/4\n",
      "7216/7216 [==============================] - 209s 29ms/step - loss: 0.4975 - get_f1: 0.4626 - accuracy: 0.7583 - val_loss: 0.5223 - val_get_f1: 0.3964 - val_accuracy: 0.7548\n",
      "Epoch 4/4\n",
      "7216/7216 [==============================] - 209s 29ms/step - loss: 0.4657 - get_f1: 0.5165 - accuracy: 0.7772 - val_loss: 0.5239 - val_get_f1: 0.4272 - val_accuracy: 0.7503\n",
      "Model evaluation 460_519.csv\n",
      "1805/1805 [==============================] - 49s 27ms/step\n",
      "[0.5203561551022727, 0.43249785900115967, 0.749030351638794]\n",
      "============completed 460_519.csv============\n",
      "\n",
      "\n",
      "============Started 520_579.csv============\n",
      "520_579.csv orginal shape: (4512, 2)\n",
      "520_579.csv Padding complete\n",
      "520_579.csv modified shape: (4512, 5120, 768)\n",
      "Train and Test Shapre: (3609, 5120, 768), (903, 5120, 768), (3609, 5), (903, 5)\n",
      "model 2\n",
      "Train on 3609 samples, validate on 225 samples\n",
      "Epoch 1/4\n",
      "3609/3609 [==============================] - 68s 19ms/step - loss: 0.5188 - get_f1: 0.3398 - accuracy: 0.7643 - val_loss: 0.4582 - val_get_f1: 0.5629 - val_accuracy: 0.8027\n",
      "Epoch 2/4\n",
      "3609/3609 [==============================] - 68s 19ms/step - loss: 0.4345 - get_f1: 0.5063 - accuracy: 0.8089 - val_loss: 0.4447 - val_get_f1: 0.5732 - val_accuracy: 0.8027\n",
      "Epoch 3/4\n",
      "3609/3609 [==============================] - 68s 19ms/step - loss: 0.3992 - get_f1: 0.5626 - accuracy: 0.8262 - val_loss: 0.4406 - val_get_f1: 0.5427 - val_accuracy: 0.7964\n",
      "Epoch 4/4\n",
      "3609/3609 [==============================] - 68s 19ms/step - loss: 0.3656 - get_f1: 0.6049 - accuracy: 0.8403 - val_loss: 0.4432 - val_get_f1: 0.5872 - val_accuracy: 0.8027\n",
      "Model evaluation 520_579.csv\n",
      "903/903 [==============================] - 16s 18ms/step\n",
      "[0.4476630037541141, 0.5320450067520142, 0.8017719984054565]\n",
      "============completed 520_579.csv============\n",
      "\n",
      "\n",
      "============Started 580_629.csv============\n",
      "580_629.csv orginal shape: (8339, 2)\n",
      "580_629.csv Padding complete\n",
      "580_629.csv modified shape: (8339, 5120, 768)\n",
      "Train and Test Shapre: (6671, 5120, 768), (1668, 5120, 768), (6671, 3), (1668, 3)\n",
      "model 1\n",
      "Train on 6671 samples, validate on 417 samples\n",
      "Epoch 1/4\n",
      "6671/6671 [==============================] - 126s 19ms/step - loss: 0.6418 - get_f1: 0.5661 - accuracy: 0.6407 - val_loss: 0.6001 - val_get_f1: 0.5709 - val_accuracy: 0.6691\n",
      "Epoch 2/4\n",
      "6671/6671 [==============================] - 125s 19ms/step - loss: 0.5748 - get_f1: 0.6446 - accuracy: 0.6971 - val_loss: 0.5990 - val_get_f1: 0.5897 - val_accuracy: 0.6787\n",
      "Epoch 3/4\n",
      "6671/6671 [==============================] - 125s 19ms/step - loss: 0.5279 - get_f1: 0.6911 - accuracy: 0.7324 - val_loss: 0.5912 - val_get_f1: 0.5895 - val_accuracy: 0.6803\n",
      "Epoch 4/4\n",
      "6671/6671 [==============================] - 125s 19ms/step - loss: 0.4728 - get_f1: 0.7378 - accuracy: 0.7711 - val_loss: 0.6076 - val_get_f1: 0.6237 - val_accuracy: 0.6707\n",
      "Model evaluation 580_629.csv\n",
      "1668/1668 [==============================] - 29s 18ms/step\n",
      "[0.5912978883555753, 0.6261874437332153, 0.6814548373222351]\n",
      "============completed 580_629.csv============\n",
      "\n",
      "\n",
      "============Started 630_679__740_759__760_779.csv============\n",
      "630_679__740_759__760_779.csv orginal shape: (1852, 2)\n",
      "630_679__740_759__760_779.csv Padding complete\n",
      "630_679__740_759__760_779.csv modified shape: (1852, 5120, 768)\n",
      "Train and Test Shapre: (1481, 5120, 768), (371, 5120, 768), (1481, 4), (371, 4)\n",
      "model 1\n",
      "Train on 1481 samples, validate on 92 samples\n",
      "Epoch 1/4\n",
      "1481/1481 [==============================] - 28s 19ms/step - loss: 0.6030 - get_f1: 0.6206 - accuracy: 0.6820 - val_loss: 0.5504 - val_get_f1: 0.6975 - val_accuracy: 0.7391\n",
      "Epoch 2/4\n",
      "1481/1481 [==============================] - 27s 18ms/step - loss: 0.5285 - get_f1: 0.6750 - accuracy: 0.7377 - val_loss: 0.5426 - val_get_f1: 0.6686 - val_accuracy: 0.7011\n",
      "Epoch 3/4\n",
      "1481/1481 [==============================] - 27s 18ms/step - loss: 0.5055 - get_f1: 0.6751 - accuracy: 0.7454 - val_loss: 0.5240 - val_get_f1: 0.6920 - val_accuracy: 0.7310\n",
      "Epoch 4/4\n",
      "1481/1481 [==============================] - 27s 18ms/step - loss: 0.4727 - get_f1: 0.7098 - accuracy: 0.7650 - val_loss: 0.5106 - val_get_f1: 0.7316 - val_accuracy: 0.7609\n",
      "Model evaluation 630_679__740_759__760_779.csv\n",
      "371/371 [==============================] - 6s 17ms/step\n",
      "[0.504351240846346, 0.7127304673194885, 0.7587600946426392]\n",
      "============completed 630_679__740_759__760_779.csv============\n",
      "\n",
      "\n",
      "============Started 710-739.csv============\n",
      "710-739.csv orginal shape: (2197, 2)\n",
      "710-739.csv Padding complete\n",
      "710-739.csv modified shape: (2197, 5120, 768)\n",
      "Train and Test Shapre: (1757, 5120, 768), (440, 5120, 768), (1757, 2), (440, 2)\n",
      "model 1\n",
      "Train on 1757 samples, validate on 110 samples\n",
      "Epoch 1/4\n",
      "1757/1757 [==============================] - 33s 19ms/step - loss: 0.7087 - get_f1: 0.6212 - accuracy: 0.5751 - val_loss: 0.7037 - val_get_f1: 0.6150 - val_accuracy: 0.5818\n",
      "Epoch 2/4\n",
      "1757/1757 [==============================] - 33s 19ms/step - loss: 0.6114 - get_f1: 0.6909 - accuracy: 0.6602 - val_loss: 0.7215 - val_get_f1: 0.5981 - val_accuracy: 0.5727\n",
      "Epoch 3/4\n",
      "1757/1757 [==============================] - 33s 19ms/step - loss: 0.5290 - get_f1: 0.7586 - accuracy: 0.7405 - val_loss: 0.7052 - val_get_f1: 0.5876 - val_accuracy: 0.5500\n",
      "Epoch 4/4\n",
      "1757/1757 [==============================] - 33s 19ms/step - loss: 0.4221 - get_f1: 0.8275 - accuracy: 0.8176 - val_loss: 0.7790 - val_get_f1: 0.5808 - val_accuracy: 0.5636\n",
      "Model evaluation 710-739.csv\n",
      "440/440 [==============================] - 8s 18ms/step\n",
      "[0.7678304076194763, 0.5658048987388611, 0.5579545497894287]\n",
      "============completed 710-739.csv============\n",
      "\n",
      "\n",
      "============Started 780-799.csv============\n",
      "780-799.csv orginal shape: (3784, 2)\n",
      "780-799.csv Padding complete\n",
      "780-799.csv modified shape: (3784, 5120, 768)\n",
      "Train and Test Shapre: (3027, 5120, 768), (757, 5120, 768), (3027, 5), (757, 5)\n",
      "model 2\n",
      "Train on 3027 samples, validate on 189 samples\n",
      "Epoch 1/4\n",
      "3027/3027 [==============================] - 57s 19ms/step - loss: 0.5262 - get_f1: 0.1910 - accuracy: 0.7666 - val_loss: 0.4374 - val_get_f1: 0.3174 - val_accuracy: 0.8138\n",
      "Epoch 2/4\n",
      "3027/3027 [==============================] - 57s 19ms/step - loss: 0.4355 - get_f1: 0.3567 - accuracy: 0.8079 - val_loss: 0.4089 - val_get_f1: 0.3970 - val_accuracy: 0.8180\n",
      "Epoch 3/4\n",
      "3027/3027 [==============================] - 57s 19ms/step - loss: 0.3940 - get_f1: 0.4654 - accuracy: 0.8268 - val_loss: 0.4108 - val_get_f1: 0.4426 - val_accuracy: 0.8148\n",
      "Epoch 4/4\n",
      "3027/3027 [==============================] - 57s 19ms/step - loss: 0.3510 - get_f1: 0.5359 - accuracy: 0.8457 - val_loss: 0.4069 - val_get_f1: 0.4596 - val_accuracy: 0.8212\n",
      "Model evaluation 780-799.csv\n",
      "757/757 [==============================] - 13s 18ms/step\n",
      "[0.40454742462033483, 0.44852471351623535, 0.8237780332565308]\n",
      "============completed 780-799.csv============\n",
      "\n",
      "\n",
      "============Started 800-999.csv============\n",
      "800-999.csv orginal shape: (4454, 2)\n",
      "800-999.csv Padding complete\n",
      "800-999.csv modified shape: (4454, 5120, 768)\n",
      "Train and Test Shapre: (3563, 5120, 768), (891, 5120, 768), (3563, 4), (891, 4)\n",
      "model 1\n",
      "Train on 3563 samples, validate on 222 samples\n",
      "Epoch 1/4\n",
      "3563/3563 [==============================] - 64s 18ms/step - loss: 0.4671 - get_f1: 0.5146 - accuracy: 0.7963 - val_loss: 0.4230 - val_get_f1: 0.5668 - val_accuracy: 0.8221\n",
      "Epoch 2/4\n",
      "3563/3563 [==============================] - 64s 18ms/step - loss: 0.3795 - get_f1: 0.5989 - accuracy: 0.8363 - val_loss: 0.4233 - val_get_f1: 0.5826 - val_accuracy: 0.8255\n",
      "Epoch 3/4\n",
      "3563/3563 [==============================] - 64s 18ms/step - loss: 0.3261 - get_f1: 0.6707 - accuracy: 0.8623 - val_loss: 0.4320 - val_get_f1: 0.5698 - val_accuracy: 0.8209\n",
      "Epoch 4/4\n",
      "3563/3563 [==============================] - 64s 18ms/step - loss: 0.2814 - get_f1: 0.7233 - accuracy: 0.8822 - val_loss: 0.4499 - val_get_f1: 0.5781 - val_accuracy: 0.8221\n",
      "Model evaluation 800-999.csv\n",
      "891/891 [==============================] - 15s 17ms/step\n",
      "[0.436425765924047, 0.5538028478622437, 0.8136925101280212]\n",
      "============completed 800-999.csv============\n",
      "\n",
      "\n",
      "============Started E_V.csv============\n",
      "E_V.csv orginal shape: (5124, 2)\n",
      "E_V.csv Padding complete\n",
      "E_V.csv modified shape: (5124, 5120, 768)\n",
      "Train and Test Shapre: (4099, 5120, 768), (1025, 5120, 768), (4099, 7), (1025, 7)\n",
      "model 2\n",
      "Train on 4099 samples, validate on 256 samples\n",
      "Epoch 1/4\n",
      "4099/4099 [==============================] - 79s 19ms/step - loss: 0.4282 - get_f1: 0.4714 - accuracy: 0.7805 - val_loss: 0.3139 - val_get_f1: 0.5717 - val_accuracy: 0.8387\n",
      "Epoch 2/4\n",
      "4099/4099 [==============================] - 79s 19ms/step - loss: 0.3415 - get_f1: 0.5423 - accuracy: 0.8204 - val_loss: 0.3033 - val_get_f1: 0.5798 - val_accuracy: 0.8404\n",
      "Epoch 3/4\n",
      "4099/4099 [==============================] - 79s 19ms/step - loss: 0.3145 - get_f1: 0.5828 - accuracy: 0.8369 - val_loss: 0.3022 - val_get_f1: 0.6000 - val_accuracy: 0.8443\n",
      "Epoch 4/4\n",
      "4099/4099 [==============================] - 79s 19ms/step - loss: 0.2936 - get_f1: 0.6285 - accuracy: 0.8518 - val_loss: 0.3006 - val_get_f1: 0.5965 - val_accuracy: 0.8371\n",
      "Model evaluation E_V.csv\n",
      "1025/1025 [==============================] - 18s 18ms/step\n",
      "[0.3022937894158247, 0.609225869178772, 0.8380486965179443]\n",
      "============completed E_V.csv============\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "history_list = []\n",
    "file_name_LIST = ['460_519.csv','520_579.csv','580_629.csv','630_679__740_759__760_779.csv', '710-739.csv','780-799.csv','800-999.csv','E_V.csv']\n",
    "1. #file_name_LIST = ['001_139.csv','140_239.csv','240_279.csv','800-999.csv']\n",
    "#file_name_LIST = ['240_279_1.csv']\n",
    "#file_name_LIST = ['630_679__740_759__760_779.csv']\n",
    "\n",
    "for file_name in file_name_LIST:\n",
    "    print('\\n\\n============Started '+file_name+'============')\n",
    "    CHAPTER_PIVOT_DF = pd.read_csv('Layer-2/'+file_name, sep=',', header = 0)\\\n",
    "                        .astype({'HADM_ID': 'str'}).set_index('HADM_ID')\n",
    "    HADM_ID_LIST = list(CHAPTER_PIVOT_DF.index)\n",
    "    embeddings_np = embeddings_np_complete[np.isin(embeddings_np_complete[:,0], HADM_ID_LIST)]\n",
    "    print(file_name+' orginal shape: '+str(embeddings_np.shape))\n",
    "    HADM_ID_LIST = embeddings_np[:,0].copy()\n",
    "    embeddings = embeddings_np[:,1].copy()\n",
    "    \n",
    "    #Zero Pad embeddings\n",
    "    embeddings_padded = [padding(embeddings_ITEM) for embeddings_ITEM in embeddings]\n",
    "    del(embeddings)\n",
    "    gc.collect()\n",
    "    print(file_name+' Padding complete')\n",
    "\n",
    "    #Reshape embeddings\n",
    "    #embeddings_concat = np.array([np.concatenate(i) for i in embeddings_padded])\n",
    "    embeddings_concat = np.array(embeddings_padded).reshape(len(embeddings_padded), 20*256, 768)\n",
    "    print(file_name+' modified shape: '+str(embeddings_concat.shape))\n",
    "    del(embeddings_padded)\n",
    "    gc.collect()\n",
    "    \n",
    "    X_train2, X_test2, y_train2, y_test2 = split_for_train(HADM_ID_LIST, CHAPTER_PIVOT_DF, embeddings_concat)\n",
    "    print('Train and Test Shapre: '+str(X_train2.shape)+', '+str(X_test2.shape)+', '+str(y_train2.shape)+', '+str(y_test2.shape))\n",
    "    X_val = X_test2[:int(0.25*len(X_test2))]\n",
    "    y_val = y_test2[:int(0.25*len(y_test2))]\n",
    "    del(HADM_ID_LIST)\n",
    "    del(CHAPTER_PIVOT_DF)\n",
    "    del(embeddings_concat)\n",
    "    gc.collect()\n",
    "    \n",
    "    #call model\n",
    "    label_len = y_train2.shape[1]\n",
    "    model = get_model(label_len)\n",
    "    opt = keras.optimizers.Adam(lr=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[get_f1, 'accuracy'])\n",
    "    history = model.fit(X_train2, y_train2, epochs=4,batch_size=32, verbose=1, validation_data = (X_val,y_val))\n",
    "    \n",
    "    #evaluate model\n",
    "    print('Model evaluation '+file_name)\n",
    "    score = model.evaluate(X_test2, y_test2, verbose=1)\n",
    "    print(score)\n",
    "    \n",
    "    #save model evaluation and history metrics\n",
    "    score_list.append(score)\n",
    "    history_list.append(history.history)\n",
    "    \n",
    "    #save model\n",
    "    model_json = model.to_json()\n",
    "    with open(\"/home/ec2-user/SageMaker/Models/model_\"+file_name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"/home/ec2-user/SageMaker/Models/model_\"+file_name+\".h5\")\n",
    "    print('============completed '+file_name+'============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============Started adverse_effect.csv============\n",
      "adverse_effect.csv orginal shape: (6339, 2)\n",
      "adverse_effect.csv Padding complete\n",
      "adverse_effect.csv modified shape: (6339, 5120, 768)\n",
      "Train and Test Shapre: (5071, 5120, 768), (1268, 5120, 768), (5071, 5), (1268, 5)\n",
      "model 2\n",
      "Train on 5071 samples, validate on 317 samples\n",
      "Epoch 1/4\n",
      "5071/5071 [==============================] - 93s 18ms/step - loss: 0.6137 - get_f1: 0.2469 - accuracy: 0.6700 - val_loss: 0.5725 - val_get_f1: 0.1195 - val_accuracy: 0.7054\n",
      "Epoch 2/4\n",
      "5071/5071 [==============================] - 98s 19ms/step - loss: 0.5610 - get_f1: 0.3124 - accuracy: 0.7078 - val_loss: 0.5533 - val_get_f1: 0.3006 - val_accuracy: 0.7091\n",
      "Epoch 3/4\n",
      "5071/5071 [==============================] - 98s 19ms/step - loss: 0.5343 - get_f1: 0.3958 - accuracy: 0.7283 - val_loss: 0.5553 - val_get_f1: 0.3046 - val_accuracy: 0.7136\n",
      "Epoch 4/4\n",
      "5071/5071 [==============================] - 98s 19ms/step - loss: 0.5076 - get_f1: 0.4448 - accuracy: 0.7428 - val_loss: 0.5521 - val_get_f1: 0.3398 - val_accuracy: 0.7123\n",
      "Model evaluation adverse_effect.csv\n",
      "1268/1268 [==============================] - 23s 18ms/step\n",
      "[0.5443361209770107, 0.3635789752006531, 0.7187696695327759]\n",
      "============completed adverse_effect.csv============\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "history_list = []\n",
    "file_name_LIST = ['adverse_effect.csv']\n",
    "1. #file_name_LIST = ['001_139.csv','140_239.csv','240_279.csv','800-999.csv']\n",
    "#file_name_LIST = ['240_279_1.csv']\n",
    "#file_name_LIST = ['630_679__740_759__760_779.csv']\n",
    "\n",
    "for file_name in file_name_LIST:\n",
    "    print('\\n\\n============Started '+file_name+'============')\n",
    "    CHAPTER_PIVOT_DF = pd.read_csv('Layer-2/'+file_name, sep=',', header = 0)\\\n",
    "                        .astype({'HADM_ID': 'str'}).set_index('HADM_ID')\n",
    "    HADM_ID_LIST = list(CHAPTER_PIVOT_DF.index)\n",
    "    embeddings_np = embeddings_np_complete[np.isin(embeddings_np_complete[:,0], HADM_ID_LIST)]\n",
    "    print(file_name+' orginal shape: '+str(embeddings_np.shape))\n",
    "    HADM_ID_LIST = embeddings_np[:,0].copy()\n",
    "    embeddings = embeddings_np[:,1].copy()\n",
    "    \n",
    "    #Zero Pad embeddings\n",
    "    embeddings_padded = [padding(embeddings_ITEM) for embeddings_ITEM in embeddings]\n",
    "    del(embeddings)\n",
    "    gc.collect()\n",
    "    print(file_name+' Padding complete')\n",
    "\n",
    "    #Reshape embeddings\n",
    "    #embeddings_concat = np.array([np.concatenate(i) for i in embeddings_padded])\n",
    "    embeddings_concat = np.array(embeddings_padded).reshape(len(embeddings_padded), 20*256, 768)\n",
    "    print(file_name+' modified shape: '+str(embeddings_concat.shape))\n",
    "    del(embeddings_padded)\n",
    "    gc.collect()\n",
    "    \n",
    "    X_train2, X_test2, y_train2, y_test2 = split_for_train(HADM_ID_LIST, CHAPTER_PIVOT_DF, embeddings_concat)\n",
    "    print('Train and Test Shapre: '+str(X_train2.shape)+', '+str(X_test2.shape)+', '+str(y_train2.shape)+', '+str(y_test2.shape))\n",
    "    X_val = X_test2[:int(0.25*len(X_test2))]\n",
    "    y_val = y_test2[:int(0.25*len(y_test2))]\n",
    "    del(HADM_ID_LIST)\n",
    "    del(CHAPTER_PIVOT_DF)\n",
    "    del(embeddings_concat)\n",
    "    gc.collect()\n",
    "    \n",
    "    #call model\n",
    "    label_len = y_train2.shape[1]\n",
    "    model = get_model(label_len)\n",
    "    opt = keras.optimizers.Adam(lr=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[get_f1, 'accuracy'])\n",
    "    history = model.fit(X_train2, y_train2, epochs=4,batch_size=32, verbose=1, validation_data = (X_val,y_val))\n",
    "    \n",
    "    #evaluate model\n",
    "    print('Model evaluation '+file_name)\n",
    "    score = model.evaluate(X_test2, y_test2, verbose=1)\n",
    "    print(score)\n",
    "    \n",
    "    #save model evaluation and history metrics\n",
    "    score_list.append(score)\n",
    "    history_list.append(history.history)\n",
    "    \n",
    "    #save model\n",
    "    model_json = model.to_json()\n",
    "    with open(\"/home/ec2-user/SageMaker/Models/model_\"+file_name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"/home/ec2-user/SageMaker/Models/model_\"+file_name+\".h5\")\n",
    "    print('============completed '+file_name+'============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_LIST = ['001_139.csv','140_239.csv','240_279.csv','280_289.csv','290_319.csv','320_389.csv','390_459.csv'\n",
    ",'460_519.csv','520_579.csv','580_629.csv','630_679__740_759__760_779.csv', '710-739.csv','780-799.csv','800-999.csv','E_V.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,724,308\n",
      "Trainable params: 2,625,988\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 2,724,243\n",
      "Trainable params: 2,625,923\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,724,308\n",
      "Trainable params: 2,625,988\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 2,724,243\n",
      "Trainable params: 2,625,923\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,724,308\n",
      "Trainable params: 2,625,988\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,724,308\n",
      "Trainable params: 2,625,988\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 256)               5234944   \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 5,374,806\n",
      "Trainable params: 5,276,486\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               5234944   \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 5,374,741\n",
      "Trainable params: 5,276,421\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 256)               5234944   \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 5,374,741\n",
      "Trainable params: 5,276,421\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 2,724,243\n",
      "Trainable params: 2,625,923\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,724,308\n",
      "Trainable params: 2,625,988\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,724,178\n",
      "Trainable params: 2,625,858\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 256)               5234944   \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 5,374,741\n",
      "Trainable params: 5,276,421\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 128)               2617472   \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,724,308\n",
      "Trainable params: 2,625,988\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 5120, 768)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5113, 16)          98320     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 20448)             0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 256)               5234944   \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 5,374,871\n",
      "Trainable params: 5,276,551\n",
      "Non-trainable params: 98,320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load chapeter model weights\n",
    "for file_name in file_name_LIST:\n",
    "    chapter_model = None\n",
    "    json_file = open('/home/ec2-user/SageMaker/Models/model_'+file_name+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    chapter_model = model_from_json(loaded_model_json)\n",
    "    opt = keras.optimizers.Adam(lr=0.001)\n",
    "    # load weights into new model\n",
    "    chapter_model.load_weights('/home/ec2-user/SageMaker/Models/model_'+file_name+'.h5')\n",
    "    chapter_model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
