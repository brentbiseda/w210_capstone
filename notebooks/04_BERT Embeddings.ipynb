{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Word Embeddings from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "import logging\n",
    "import custom_sentence_tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imp.reload(custom_sentence_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read and preprocess Discharge summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_DF = pd.read_csv('C:/Users/kfpj179/Desktop/Final Project/data/NOTEEVENTS.csv', \n",
    "                            sep=',', header = 0,\n",
    "                            usecols = lambda column : column not in [\"CHARTTIME\" , \"STORETIME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Concat all discharge summaries at admission level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59652"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOTEEVENTS_DISCHARGE_DF = NOTEEVENTS_DF[(NOTEEVENTS_DF['CATEGORY']=='Discharge summary') & \n",
    "                                       (NOTEEVENTS_DF['ISERROR'].isnull())][['HADM_ID','CATEGORY','TEXT']]\n",
    "NOTEEVENTS_DISCHARGE_DF['HADM_ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_DISCHARGE_COMB_DF = NOTEEVENTS_DISCHARGE_DF.astype({'HADM_ID': 'str'}).copy()\n",
    "NOTEEVENTS_DISCHARGE_COMB_DF['TEXT'] = NOTEEVENTS_DISCHARGE_COMB_DF.groupby(['HADM_ID','CATEGORY'])['TEXT']\\\n",
    "                            .transform(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_DISCHARGE_COMB_DF = NOTEEVENTS_DISCHARGE_COMB_DF.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>167853</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>107527</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>167118</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>196489</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>135453</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HADM_ID           CATEGORY  \\\n",
       "0  167853  Discharge summary   \n",
       "1  107527  Discharge summary   \n",
       "2  167118  Discharge summary   \n",
       "3  196489  Discharge summary   \n",
       "4  135453  Discharge summary   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
       "2  Admission Date:  [**2119-5-4**]              D...  \n",
       "3  Admission Date:  [**2124-7-21**]              ...  \n",
       "4  Admission Date:  [**2162-3-3**]              D...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOTEEVENTS_DISCHARGE_COMB_DF['HADM_ID'] = NOTEEVENTS_DISCHARGE_COMB_DF['HADM_ID'].transform(lambda x:x[:6])\n",
    "NOTEEVENTS_DISCHARGE_COMB_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_DISCHARGE_COMB_DF['HADM_ID'].count()\n",
    "NOTEEVENTS_DF = None\n",
    "NOTEEVENTS_DISCHARGE_DF = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Preprocessing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27902</td>\n",
       "      <td>194356</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2186-4-11**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18286</td>\n",
       "      <td>175191</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2118-12-26**]     Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51539</td>\n",
       "      <td>147153</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2194-6-27**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55968</td>\n",
       "      <td>137467</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2150-4-11**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44874</td>\n",
       "      <td>139922</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2181-3-8**]              D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HADM_ID           CATEGORY  \\\n",
       "27902  194356  Discharge summary   \n",
       "18286  175191  Discharge summary   \n",
       "51539  147153  Discharge summary   \n",
       "55968  137467  Discharge summary   \n",
       "44874  139922  Discharge summary   \n",
       "\n",
       "                                                    TEXT  \n",
       "27902  Admission Date:  [**2186-4-11**]              ...  \n",
       "18286  Admission Date:  [**2118-12-26**]     Discharg...  \n",
       "51539  Admission Date:  [**2194-6-27**]              ...  \n",
       "55968  Admission Date:  [**2150-4-11**]              ...  \n",
       "44874  Admission Date:  [**2181-3-8**]              D...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTEEVENTS_DISCHARGE_NLP_DF = NOTEEVENTS_DISCHARGE_COMB_DF.sample(n=10, random_state=1).copy()\n",
    "NOTEEVENTS_DISCHARGE_NLP_DF = NOTEEVENTS_DISCHARGE_COMB_DF.copy()\n",
    "NOTEEVENTS_DISCHARGE_NLP_DF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_DISCHARGE_COMB_DF = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Replace medical abbrivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    replace_LIST = [\n",
    "                     ['dr\\.','']\n",
    "                    ,['DR\\.','']\n",
    "                    ,['m\\.d\\.','']\n",
    "                    ,['M\\.D\\.','']\n",
    "                    ,['p\\.o', 'orally']\n",
    "                    ,['P\\.O', 'orally']\n",
    "                    ,['q\\.d\\.', 'once a day']\n",
    "                    ,['Q\\.D\\.', 'once a day']\n",
    "                    ,['I\\.M\\.', 'intramuscularly']\n",
    "                    ,['i\\.m\\.', 'intramuscularly']\n",
    "                    ,['b\\.i\\.d\\.', 'twice a day']\n",
    "                    ,['B\\.I\\.D\\.', 'twice a day']\n",
    "                    ,['Subq\\.', 'subcutaneous']\n",
    "                    ,['SUBQ\\.', 'subcutaneous']\n",
    "                    ,['t\\.i\\.d\\.', 'three times a day']\n",
    "                    ,['T\\.I\\.D\\.', 'three times a day']\n",
    "                    ,['q\\.i\\.d\\.', 'four times a day']\n",
    "                    ,['Q\\.I\\.D\\.', 'four times a day']\n",
    "                    ,['I\\.V\\.', 'intravenous']\n",
    "                    ,['i\\.v\\.', 'intravenous']\n",
    "                    ,['q\\.h\\.s\\.', 'before bed']\n",
    "                    ,['Q\\.H\\.S\\.', 'before bed']\n",
    "                    ,['O\\.D\\.', 'in the right eye']\n",
    "                    ,['o\\.d\\.', 'in the right eye']\n",
    "                    ,['5X', 'a day five times a day']\n",
    "                    ,['5x', 'a day five times a day']\n",
    "                    ,['O\\.S\\.', 'in the left eye']\n",
    "                    ,['o\\.s\\.', 'in the left eye']\n",
    "                    ,['q\\.4h', 'every four hours']\n",
    "                    ,['Q\\.4H', 'every four hours']\n",
    "                    ,['O\\.U\\.', 'in both eyes']\n",
    "                    ,['o\\.u\\.', 'in both eyes']\n",
    "                    ,['q\\.6h', 'every six hours']\n",
    "                    ,['Q\\.6H', 'every six hours']\n",
    "                    ,['q\\.o\\.d\\.', 'every other day']\n",
    "                    ,['Q\\.O\\.D\\.', 'every other day']\n",
    "                    ,['prn\\.', 'as needed']\n",
    "                    ,['PRN\\.', 'as needed']\n",
    "                    ,['[0-9]+\\.','']\n",
    "                    ,[r'\\[\\*.+\\*\\]','']\n",
    "                    ]\n",
    "\n",
    "    def preprocess_re_sub(x):\n",
    "        processed_text = x\n",
    "        for find,replace in replace_LIST:\n",
    "            processed_text=re.sub(find,replace,processed_text)\n",
    "        return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_DISCHARGE_NLP_DF['TEXT'] = NOTEEVENTS_DISCHARGE_NLP_DF['TEXT'].transform(lambda x:preprocess_re_sub(x))\n",
    "NOTEEVENTS_DISCHARGE_NLP_DF['ID'] = NOTEEVENTS_DISCHARGE_NLP_DF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27902</td>\n",
       "      <td>194356</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  \\n\\nDate of Birth:           ...</td>\n",
       "      <td>27902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18286</td>\n",
       "      <td>175191</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  \\n\\nDate of Birth:        Sex...</td>\n",
       "      <td>18286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51539</td>\n",
       "      <td>147153</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  \\n\\nDate of Birth:           ...</td>\n",
       "      <td>51539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55968</td>\n",
       "      <td>137467</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  \\n\\nDate of Birth:           ...</td>\n",
       "      <td>55968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44874</td>\n",
       "      <td>139922</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  \\n\\nDate of Birth:           ...</td>\n",
       "      <td>44874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HADM_ID           CATEGORY  \\\n",
       "27902  194356  Discharge summary   \n",
       "18286  175191  Discharge summary   \n",
       "51539  147153  Discharge summary   \n",
       "55968  137467  Discharge summary   \n",
       "44874  139922  Discharge summary   \n",
       "\n",
       "                                                    TEXT     ID  \n",
       "27902  Admission Date:  \\n\\nDate of Birth:           ...  27902  \n",
       "18286  Admission Date:  \\n\\nDate of Birth:        Sex...  18286  \n",
       "51539  Admission Date:  \\n\\nDate of Birth:           ...  51539  \n",
       "55968  Admission Date:  \\n\\nDate of Birth:           ...  55968  \n",
       "44874  Admission Date:  \\n\\nDate of Birth:           ...  44874  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOTEEVENTS_DISCHARGE_NLP_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_DISCHARGE_NLP_DF['PREPROC_TEXT'] = NOTEEVENTS_DISCHARGE_NLP_DF['TEXT']\\\n",
    "                                    .transform(lambda x:custom_sentence_tokenizer.custom_sentence_tokenizer(x \n",
    "                                                        , testing = False, verbose = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sent(x):\n",
    "    combined_sent = ''\n",
    "    combined_sent_list = []\n",
    "    for i in range(len(x)):\n",
    "        sent = x[i]\n",
    "        if sent!='.':\n",
    "            sent = re.sub('^\\s+|\\n|\\r',' ',\n",
    "            re.sub('\\s\\s|\\t|\\.|\\,||admission date:|discharge date:|date of birth:|addendum:|--|__|==','',\n",
    "                   sent.lower())).strip()\n",
    "            sent_len = len(sent.split(' '))\n",
    "            combined_sent_len = len(combined_sent.split(' '))\n",
    "            \n",
    "            if i == 0:\n",
    "                combined_sent = sent\n",
    "                \n",
    "            else:\n",
    "                # when len of sentence + combined sent < 92, combine the existin combined list with current sentence\n",
    "                if sent_len + combined_sent_len <= 64:\n",
    "                    combined_sent = combined_sent + ' . ' + sent\n",
    "                    if i == len(x) - 1:\n",
    "                        combined_sent_list.append(combined_sent) \n",
    "                else:\n",
    "                # when len is longer then append current combined sent into final list and reinitialize combined sent with current sent \n",
    "                    combined_sent_list.append(combined_sent)\n",
    "                    combined_sent = sent\n",
    "                \n",
    "    return combined_sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_DISCHARGE_NLP_DF['PREPROC_TEXT_COMB'] = NOTEEVENTS_DISCHARGE_NLP_DF['PREPROC_TEXT']\\\n",
    "                                    .transform(lambda x:combine_sent(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clinical BERT Word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_token(x):\n",
    "    tokens = []\n",
    "    for i in x:\n",
    "        tokens.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(i)))\n",
    "    return tokens\n",
    "\n",
    "NOTEEVENTS_DISCHARGE_NLP_DF['TEXT_TOKENS'] = NOTEEVENTS_DISCHARGE_NLP_DF['PREPROC_TEXT_COMB']\\\n",
    "                                                .transform(lambda x:create_token(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Explore sentence length and count of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for j in range(10):\n",
    "    arr.extend(np.array([len(i) for i in NOTEEVENTS_DISCHARGE_NLP_DF['TEXT_TOKENS'].iloc[j]]))\n",
    "arr = np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62: 0.13793103448275862\n",
      "78: 0.3146551724137931\n",
      "94: 0.6422413793103449\n",
      "110: 0.8275862068965517\n",
      "126: 0.9008620689655172\n",
      "142: 0.9224137931034483\n",
      "158: 0.9482758620689655\n",
      "174: 0.9525862068965517\n",
      "190: 0.9568965517241379\n",
      "206: 0.9568965517241379\n",
      "222: 0.9568965517241379\n",
      "238: 0.9568965517241379\n",
      "254: 0.9568965517241379\n"
     ]
    }
   ],
   "source": [
    "for i in range(62, 260, 16):\n",
    "    print(str(i) + ': '+str(len(arr[arr<=i])/len(arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Merge with chapter labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPTER_LABEL_DF = pd.read_csv('C:/Users/kfpj179/Desktop/Final Project/data/chapter_label.csv', \n",
    "                            sep=',', header = 0).astype({'HADM_ID': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_CHAPTER_DF = NOTEEVENTS_DISCHARGE_NLP_DF[['HADM_ID','TEXT_TOKENS']].set_index('HADM_ID')\\\n",
    "            .join(CHAPTER_LABEL_DF.set_index('HADM_ID'), how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare input for BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Truncate and zero pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_sent(x):\n",
    "    max_len = 126\n",
    "    sent_list = []\n",
    "    for i in x:\n",
    "        sent_len = len(i)\n",
    "        if sent_len < max_len:\n",
    "            i.extend(np.zeros(max_len - sent_len).astype(int))\n",
    "            sent_list.append(i)\n",
    "\n",
    "        else:\n",
    "            sent_list.append(i[:max_len])\n",
    "\n",
    "    return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_CHAPTER_DF['TEXT_TOKENS'] = NOTEEVENTS_CHAPTER_DF['TEXT_TOKENS'].transform(lambda x:truncate_sent(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Include cls and sep tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tags(x):\n",
    "    sent_list = []\n",
    "    for i in x:\n",
    "        sent = [101]\n",
    "        sent.extend(i)\n",
    "        sent.append(102)\n",
    "        sent_list.append(sent)\n",
    "    return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_CHAPTER_DF['TEXT_TOKENS'] = NOTEEVENTS_CHAPTER_DF['TEXT_TOKENS'].transform(lambda x:bert_tags(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_mask(x):\n",
    "    max_word = 128\n",
    "    sent_len = len(x)\n",
    "    attention_mask = []\n",
    "    for x_ITEM in x:\n",
    "        ones_list = np.ones(max_word).astype(int)\n",
    "        for j, token in enumerate(x_ITEM):\n",
    "            if token==0:\n",
    "                ones_list[j] = 0 \n",
    "        attention_mask.append(ones_list)\n",
    "\n",
    "    return attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS_CHAPTER_DF['ATTENTION'] = NOTEEVENTS_CHAPTER_DF['TEXT_TOKENS'].transform(lambda x:attention_mask(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query BERT Pretrained weights to generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Generate embeddings from clinical bert base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximately 6.5 seconds/ note on 32 GB, 1.9GHz i7 CPU; i.e, 100 hrs (4.5 days) for all notes\n",
    "embeddings = {}\n",
    "#count = 0\n",
    "for i in NOTEEVENTS_CHAPTER_DF.index:\n",
    "    #now = time.time()\n",
    "    tokens = torch.tensor(NOTEEVENTS_CHAPTER_DF.loc[i, 'TEXT_TOKENS'])\n",
    "    attention_mask = torch.tensor(NOTEEVENTS_CHAPTER_DF.loc[i, 'ATTENTION'])\n",
    "    embeddings[i] = np.array(model(tokens,attention_mask=attention_mask)[0].data)\n",
    "    #model.zero_grad()\n",
    "    #count = count + 1\n",
    "    #print(count)\n",
    "    #print(time.time()-now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Pickle the embeddings for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(embeddings, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_embedding_np = np.array(list(embeddings.items()))\n",
    "embeddings_list = list(zip(embeddings_embedding_np[:,0], [np.float16(i) for i in embeddings_embedding_np[:,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings_list.pickle', 'wb') as handle:\n",
    "    pickle.dump(embeddings_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
